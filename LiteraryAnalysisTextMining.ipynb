{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e283e81",
   "metadata": {},
   "source": [
    "# Literary Analysis: Comparing Nonfiction and Fiction through Topic Modeling and Sentiment Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e25c770",
   "metadata": {},
   "source": [
    "### ADS 509 Final Project\n",
    "##### Team 3: Claire Bentzen, Tara Dehdari, Logan Van Dine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4272e44e",
   "metadata": {},
   "source": [
    "##### Introduction\n",
    "\n",
    "In this project, we will conduct a comparative analysis of two significant literary works: \"Pride and Prejudice\" by Jane Austen (fiction) and \"A Vindication of the Rights of Woman\" by Mary Wollstonecraft (nonfiction). Both texts engage deeply with themes of gender, society, and individual rights, making them ideal for exploring the differences in language, themes, and sentiment between fiction and nonfiction.\n",
    "\n",
    "Using text mining techniques, we will analyze how each genre approaches these themes, examining the stylistic and rhetorical differences that characterize fiction versus nonfiction. Our analysis will involve data cleaning, tokenization, and the application of descriptive statistics, sentiment analysis, and topic modeling. By comparing these works, we aim to uncover the unique ways in which each genre communicates similar ideas, providing insights into the broader distinctions between fiction and nonfiction writing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f8631",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e783ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from bs4 import BeautifulSoup  \n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e266c945",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa4d2a",
   "metadata": {},
   "source": [
    "This portion scrapes and saves the full text of Pride and Prejudice and A Vindication of the Rights of Woman from Project Gutenberg. It ensures the save directory exists, extracts text from the HTML, saves it to .txt files, and verifies that the files were created successfully, showing a preview of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb50984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from 'pride_and_prejudice.txt' scraped and saved.\n",
      "File './data/pride_and_prejudice.txt' has been created successfully.\n",
      "File content preview:\n",
      "\n",
      "The Project Gutenberg eBook of Pride and Prejudice\n",
      "Title: Pride and Prejudice\n",
      "Author: Jane Austen\n",
      "Re\n",
      "Text from 'the_awakening.txt' scraped and saved.\n",
      "File './data/the_awakening.txt' has been created successfully.\n",
      "File content preview:\n",
      "\n",
      "The Project Gutenberg eBook of The Awakening, and Selected Short Stories\n",
      "Title: The Awakening, and S\n",
      "Text from 'north_and_south.txt' scraped and saved.\n",
      "File './data/north_and_south.txt' has been created successfully.\n",
      "File content preview:\n",
      "\n",
      "The Project Gutenberg eBook of North and South\n",
      "Title: North and South\n",
      "Author: Elizabeth Cleghorn Gas\n",
      "Text from 'wuthering_heights.txt' scraped and saved.\n",
      "File './data/wuthering_heights.txt' has been created successfully.\n",
      "File content preview:\n",
      "\n",
      "The Project Gutenberg eBook of Wuthering Heights\n",
      "Title: Wuthering Heights\n",
      "Author: Emily BrontÃ«\n",
      "Relea\n",
      "Text from 'vindication_of_rights_of_woman.txt' scraped and saved.\n",
      "File './data/vindication_of_rights_of_woman.txt' has been created successfully.\n",
      "File content preview:\n",
      "\n",
      "The Project Gutenberg eBook of A Vindication of the Rights of Woman\n",
      "Title: A Vindication of the Righ\n",
      "Text from 'the_enfranchisement_of_women.txt' scraped and saved.\n",
      "File './data/the_enfranchisement_of_women.txt' has been created successfully.\n",
      "File content preview:\n",
      "\n",
      "The Project Gutenberg eBook of Enfranchisement of women\n",
      "Title: Enfranchisement of women\n",
      " Reprinted f\n",
      "Text from 'on_liberty.txt' scraped and saved.\n",
      "File './data/on_liberty.txt' has been created successfully.\n",
      "File content preview:\n",
      "\n",
      "The Project Gutenberg eBook of On Liberty\n",
      "Title: On Liberty\n",
      "Author: John Stuart Mill\n",
      "Release date: J\n",
      "Text from 'the_subjection_of_women.txt' scraped and saved.\n",
      "File './data/the_subjection_of_women.txt' has been created successfully.\n",
      "File content preview:\n",
      "\n",
      "The Project Gutenberg eBook of The Subjection of Women\n",
      "Title: The Subjection of Women\n",
      "Author: John S\n"
     ]
    }
   ],
   "source": [
    "# Define the URLs for the books\n",
    "## fiction\n",
    "url_pride_prej = 'https://www.gutenberg.org/cache/epub/1342/pg1342-images.html'\n",
    "url_awakening = 'https://www.gutenberg.org/cache/epub/160/pg160-images.html'\n",
    "url_north_south = 'https://www.gutenberg.org/cache/epub/4276/pg4276-images.html'\n",
    "url_wuthering_heights = 'https://www.gutenberg.org/cache/epub/768/pg768-images.html'\n",
    "## nonfiction\n",
    "url_vin_of_women = 'https://www.gutenberg.org/cache/epub/3420/pg3420-images.html'\n",
    "url_enfranchisement = 'https://www.gutenberg.org/cache/epub/73404/pg73404-images.html'\n",
    "url_on_liberty = 'https://www.gutenberg.org/cache/epub/34901/pg34901-images.html'\n",
    "url_subjection_women = 'https://www.gutenberg.org/cache/epub/27083/pg27083-images.html'\n",
    "\n",
    "# Define the directory to save the files\n",
    "data_dir = './data'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Function to scrape and save books\n",
    "def scrape_and_save_book(url, file_name):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Check that the request was successful\n",
    "    \n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract all text from <p> tags\n",
    "    paragraphs = soup.find_all(['p', 'h1', 'h2', 'h3'])\n",
    "    book_text = '\\n'.join([para.get_text() for para in paragraphs if para.get_text().strip()])\n",
    "\n",
    "    \n",
    "    # Save the extracted text to a file\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(book_text)\n",
    "    \n",
    "    print(f\"Text from '{file_name}' scraped and saved.\")\n",
    "    \n",
    "    # Check if the file is saved and contains content\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File '{file_path}' has been created successfully.\")\n",
    "        # Check the first few lines of the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            preview = file.read(100)  # Read the first 100 characters\n",
    "            print(\"File content preview:\\n\")\n",
    "            print(preview)\n",
    "    else:\n",
    "        print(f\"Failed to create the file '{file_path}'.\")\n",
    "\n",
    "# List of Fiction book tuples\n",
    "fiction_books = [\n",
    "    (url_pride_prej, 'pride_and_prejudice.txt'),\n",
    "    (url_awakening, 'the_awakening.txt'),\n",
    "    (url_north_south, 'north_and_south.txt'),\n",
    "    (url_wuthering_heights, 'wuthering_heights.txt')\n",
    "]\n",
    "\n",
    "# Loop over the list and scrape/save each book\n",
    "for url, filename in fiction_books:\n",
    "    scrape_and_save_book(url, filename)\n",
    "\n",
    "# List of Nonfiction book tuples\n",
    "nonfiction_books = [\n",
    "    (url_vin_of_women, 'vindication_of_rights_of_woman.txt'),\n",
    "    (url_enfranchisement, 'the_enfranchisement_of_women.txt'),\n",
    "    (url_on_liberty, 'on_liberty.txt'),\n",
    "    (url_subjection_women, 'the_subjection_of_women.txt')\n",
    "]\n",
    "\n",
    "# Loop over the list and scrape/save each book\n",
    "for url, filename in nonfiction_books:\n",
    "    scrape_and_save_book(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ccb09",
   "metadata": {},
   "source": [
    "### Data Cleaning and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e67f5f",
   "metadata": {},
   "source": [
    "This section converts the raw text into a dataframe format that includes information about the books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d831fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dataframe\n",
    "books = pd.DataFrame(columns=['Title', 'Author', 'Release_Date', 'Updated_Date', 'Language', 'Credits', 'Text', 'Genre'])\n",
    "\n",
    "# Function to convert text to DataFrame\n",
    "def convert_to_df(file_name, genre):\n",
    "    # Establish file path\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    \n",
    "    # Open contents of file\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            \n",
    "            # Extract relevant sections with error handling for missing fields\n",
    "            title = re.search(r'Title:\\s*(.*)', content)\n",
    "            title = title.group(1) if title else 'Unknown'\n",
    "            \n",
    "            author = re.search(r'Author:\\s*(.*)', content)\n",
    "            author = author.group(1) if author else 'Unknown'\n",
    "            \n",
    "            release_date = re.search(r'Release date:\\s*(.*)\\[eBook', content)\n",
    "            release_date = release_date.group(1).strip() if release_date else 'Unknown'\n",
    "            \n",
    "            updated_date = re.search(r'Most recently updated:\\s*(.*)', content)\n",
    "            updated_date = updated_date.group(1) if updated_date else 'Not available'\n",
    "            \n",
    "            language = re.search(r'Language:\\s*(.*)', content)\n",
    "            language = language.group(1) if language else 'Unknown'\n",
    "            \n",
    "            credits = re.search(r'Credits:\\s*(.*)', content)\n",
    "            credits = credits.group(1) if credits else 'Not available'\n",
    "            \n",
    "            # Extract book text\n",
    "            match = re.search(r'Credits:.*?\\n(.*)', content, re.DOTALL)\n",
    "            book_text = match.group(1).strip() if match else 'No text available'\n",
    "            \n",
    "            # Dictionary for book information\n",
    "            book_info = {\n",
    "                'Title': title,\n",
    "                'Author': author,\n",
    "                'Release_Date': release_date,\n",
    "                'Updated_Date': updated_date,\n",
    "                'Language': language,\n",
    "                'Credits': credits,\n",
    "                'Text': book_text,\n",
    "                'Genre': genre  \n",
    "            }\n",
    "            \n",
    "            # Add data to books DataFrame\n",
    "            books.loc[len(books)] = book_info\n",
    "            \n",
    "    else:\n",
    "        print(f\"The file '{file_name}' does not exist.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99376f3f",
   "metadata": {},
   "source": [
    "##### Call on Dataframe Function with both texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "debdf1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list/loop to call on dataframe function\n",
    "# Combined list of  tuples for both Fiction and Nonfiction\n",
    "books_list = [\n",
    "    ('pride_and_prejudice.txt', 'Fiction'),\n",
    "    ('the_awakening.txt', 'Fiction'),\n",
    "    ('north_and_south.txt', 'Fiction'),\n",
    "    ('wuthering_heights.txt', 'Fiction'),\n",
    "    ('vindication_of_rights_of_woman.txt', 'Nonfiction'),\n",
    "    ('the_enfranchisement_of_women.txt', 'Nonfiction'),\n",
    "    ('on_liberty.txt', 'Nonfiction'),\n",
    "    ('the_subjection_of_women.txt', 'Nonfiction')\n",
    "]\n",
    "\n",
    "# Loop over the combined list and convert to DataFrame\n",
    "for filename, genre in books_list:\n",
    "    convert_to_df(filename, genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e5ba4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Release_Date</th>\n",
       "      <th>Updated_Date</th>\n",
       "      <th>Language</th>\n",
       "      <th>Credits</th>\n",
       "      <th>Text</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>June 1, 1998</td>\n",
       "      <td>June 17, 2024</td>\n",
       "      <td>English</td>\n",
       "      <td>Chuck Greif and the Online Distributed Proofre...</td>\n",
       "      <td>PREFACE.\\nList of Illustrations.\\nChapter: I.,...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Awakening, and Selected Short Stories</td>\n",
       "      <td>Kate Chopin</td>\n",
       "      <td>March 11, 2006</td>\n",
       "      <td>February 28, 2021</td>\n",
       "      <td>English</td>\n",
       "      <td>Judith Boss and David Widger</td>\n",
       "      <td>The Awakeningand Selected Short Stories\\nby Ka...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North and South</td>\n",
       "      <td>Elizabeth Cleghorn Gaskell</td>\n",
       "      <td>July 1, 2003</td>\n",
       "      <td>February 8, 2024</td>\n",
       "      <td>English</td>\n",
       "      <td>Produced by Chuck Greif and the Online Distrib...</td>\n",
       "      <td>NORTH AND SOUTH.\\nâSHE LAY CURLED UPON THE SOF...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>Emily BrontÃ«</td>\n",
       "      <td>December 1, 1996</td>\n",
       "      <td>January 18, 2022</td>\n",
       "      <td>English</td>\n",
       "      <td>David Price</td>\n",
       "      <td>Wuthering Heights\\nby Emily BrontÃ«\\nCHAPTER I\\...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Vindication of the Rights of Woman</td>\n",
       "      <td>Mary Wollstonecraft</td>\n",
       "      <td>September 1, 2002</td>\n",
       "      <td>January 8, 2021</td>\n",
       "      <td>English</td>\n",
       "      <td>This etext was produced by Amy E Zelmer, Col C...</td>\n",
       "      <td>This etext was produced by\\nAmy E Zelmer  &lt;a.z...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title                      Author  \\\n",
       "0                        Pride and Prejudice                 Jane Austen   \n",
       "1  The Awakening, and Selected Short Stories                 Kate Chopin   \n",
       "2                            North and South  Elizabeth Cleghorn Gaskell   \n",
       "3                          Wuthering Heights                Emily BrontÃ«   \n",
       "4       A Vindication of the Rights of Woman         Mary Wollstonecraft   \n",
       "\n",
       "        Release_Date       Updated_Date Language  \\\n",
       "0       June 1, 1998      June 17, 2024  English   \n",
       "1     March 11, 2006  February 28, 2021  English   \n",
       "2       July 1, 2003   February 8, 2024  English   \n",
       "3   December 1, 1996   January 18, 2022  English   \n",
       "4  September 1, 2002    January 8, 2021  English   \n",
       "\n",
       "                                             Credits  \\\n",
       "0  Chuck Greif and the Online Distributed Proofre...   \n",
       "1                       Judith Boss and David Widger   \n",
       "2  Produced by Chuck Greif and the Online Distrib...   \n",
       "3                                        David Price   \n",
       "4  This etext was produced by Amy E Zelmer, Col C...   \n",
       "\n",
       "                                                Text       Genre  \n",
       "0  PREFACE.\\nList of Illustrations.\\nChapter: I.,...     Fiction  \n",
       "1  The Awakeningand Selected Short Stories\\nby Ka...     Fiction  \n",
       "2  NORTH AND SOUTH.\\nâSHE LAY CURLED UPON THE SOF...     Fiction  \n",
       "3  Wuthering Heights\\nby Emily BrontÃ«\\nCHAPTER I\\...     Fiction  \n",
       "4  This etext was produced by\\nAmy E Zelmer  <a.z...  Nonfiction  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the books DataFrame to check the loaded texts\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b907b5a",
   "metadata": {},
   "source": [
    "This section cleans and tokenizes the Text column with the following steps:\n",
    "1. Cast to lowercase\n",
    "2. Remove punctuation\n",
    "3. Tokenize\n",
    "4. Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c09cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctuation\n",
    "punctuation = set(punctuation) \n",
    "\n",
    "# Removes punctuation\n",
    "def remove_punctuation(text, punct_set=punctuation): \n",
    "    \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Removes stopwords\n",
    "def remove_stop(tokens):\n",
    "    \n",
    "    tokens = [word for word in tokens if word not in sw]\n",
    "    \n",
    "    return(tokens)\n",
    " \n",
    "\n",
    "# Tokenize the text\n",
    "def tokenize(text):     \n",
    "    \n",
    "    return text.split()\n",
    "\n",
    "# Applies the pipeline\n",
    "def pipeline(text): \n",
    "    \n",
    "    text = str.lower(text)\n",
    "    text = remove_punctuation(text)\n",
    "    tokens = tokenize(text)\n",
    "    tokens = remove_stop(tokens)\n",
    "    \n",
    "    return(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f2b85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts Text column to string\n",
    "books['Text'] = books['Text'].astype(str)\n",
    "\n",
    "# Cleans Text\n",
    "books['Cleaned_Text'] = books['Text'].apply(pipeline)\n",
    "\n",
    "# Tokenizes Text\n",
    "books['Tokens'] = books['Cleaned_Text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e97367f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Release_Date</th>\n",
       "      <th>Updated_Date</th>\n",
       "      <th>Language</th>\n",
       "      <th>Credits</th>\n",
       "      <th>Text</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>June 1, 1998</td>\n",
       "      <td>June 17, 2024</td>\n",
       "      <td>English</td>\n",
       "      <td>Chuck Greif and the Online Distributed Proofre...</td>\n",
       "      <td>PREFACE.\\nList of Illustrations.\\nChapter: I.,...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>preface list illustrations chapter ii iii iv v...</td>\n",
       "      <td>[preface, list, illustrations, chapter, ii, ii...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Awakening, and Selected Short Stories</td>\n",
       "      <td>Kate Chopin</td>\n",
       "      <td>March 11, 2006</td>\n",
       "      <td>February 28, 2021</td>\n",
       "      <td>English</td>\n",
       "      <td>Judith Boss and David Widger</td>\n",
       "      <td>The Awakeningand Selected Short Stories\\nby Ka...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>awakeningand selected short stories kate chopi...</td>\n",
       "      <td>[awakeningand, selected, short, stories, kate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North and South</td>\n",
       "      <td>Elizabeth Cleghorn Gaskell</td>\n",
       "      <td>July 1, 2003</td>\n",
       "      <td>February 8, 2024</td>\n",
       "      <td>English</td>\n",
       "      <td>Produced by Chuck Greif and the Online Distrib...</td>\n",
       "      <td>NORTH AND SOUTH.\\nâSHE LAY CURLED UPON THE SOF...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>north south âshe lay curled upon sofa back dra...</td>\n",
       "      <td>[north, south, âshe, lay, curled, upon, sofa, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>Emily BrontÃ«</td>\n",
       "      <td>December 1, 1996</td>\n",
       "      <td>January 18, 2022</td>\n",
       "      <td>English</td>\n",
       "      <td>David Price</td>\n",
       "      <td>Wuthering Heights\\nby Emily BrontÃ«\\nCHAPTER I\\...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>wuthering heights emily brontÃ« chapter 1801âi ...</td>\n",
       "      <td>[wuthering, heights, emily, brontÃ«, chapter, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Vindication of the Rights of Woman</td>\n",
       "      <td>Mary Wollstonecraft</td>\n",
       "      <td>September 1, 2002</td>\n",
       "      <td>January 8, 2021</td>\n",
       "      <td>English</td>\n",
       "      <td>This etext was produced by Amy E Zelmer, Col C...</td>\n",
       "      <td>This etext was produced by\\nAmy E Zelmer  &lt;a.z...</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>etext produced amy e zelmer azelmercqueduau co...</td>\n",
       "      <td>[etext, produced, amy, e, zelmer, azelmercqued...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Enfranchisement of women</td>\n",
       "      <td>Harriet Hardy Taylor Mill</td>\n",
       "      <td>April 16, 2024</td>\n",
       "      <td>Not available</td>\n",
       "      <td>English</td>\n",
       "      <td>Claudine Corbasson and the Online Distributed ...</td>\n",
       "      <td>To the reader\\nFootnotes\\n1\\nENFRANCHISEMENT O...</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>reader footnotes 1 enfranchisement women mrs j...</td>\n",
       "      <td>[reader, footnotes, 1, enfranchisement, women,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>On Liberty</td>\n",
       "      <td>John Stuart Mill</td>\n",
       "      <td>January 10, 2011</td>\n",
       "      <td>August 12, 2019</td>\n",
       "      <td>English</td>\n",
       "      <td>Produced by Curtis Weyant, Martin Pettit and t...</td>\n",
       "      <td>Distributed Proofreading Team at http://www.pg...</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>distributed proofreading team httpwwwpgdpnet p...</td>\n",
       "      <td>[distributed, proofreading, team, httpwwwpgdpn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Subjection of Women</td>\n",
       "      <td>John Stuart Mill</td>\n",
       "      <td>October 28, 2008</td>\n",
       "      <td>January 25, 2021</td>\n",
       "      <td>English</td>\n",
       "      <td>Produced by Michael Roe and the Online Distrib...</td>\n",
       "      <td>Proofreading Team at https://www.pgdp.net (Thi...</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>proofreading team httpswwwpgdpnet file produce...</td>\n",
       "      <td>[proofreading, team, httpswwwpgdpnet, file, pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title                      Author  \\\n",
       "0                        Pride and Prejudice                 Jane Austen   \n",
       "1  The Awakening, and Selected Short Stories                 Kate Chopin   \n",
       "2                            North and South  Elizabeth Cleghorn Gaskell   \n",
       "3                          Wuthering Heights                Emily BrontÃ«   \n",
       "4       A Vindication of the Rights of Woman         Mary Wollstonecraft   \n",
       "5                   Enfranchisement of women   Harriet Hardy Taylor Mill   \n",
       "6                                 On Liberty            John Stuart Mill   \n",
       "7                    The Subjection of Women            John Stuart Mill   \n",
       "\n",
       "        Release_Date       Updated_Date Language  \\\n",
       "0       June 1, 1998      June 17, 2024  English   \n",
       "1     March 11, 2006  February 28, 2021  English   \n",
       "2       July 1, 2003   February 8, 2024  English   \n",
       "3   December 1, 1996   January 18, 2022  English   \n",
       "4  September 1, 2002    January 8, 2021  English   \n",
       "5     April 16, 2024      Not available  English   \n",
       "6   January 10, 2011    August 12, 2019  English   \n",
       "7   October 28, 2008   January 25, 2021  English   \n",
       "\n",
       "                                             Credits  \\\n",
       "0  Chuck Greif and the Online Distributed Proofre...   \n",
       "1                       Judith Boss and David Widger   \n",
       "2  Produced by Chuck Greif and the Online Distrib...   \n",
       "3                                        David Price   \n",
       "4  This etext was produced by Amy E Zelmer, Col C...   \n",
       "5  Claudine Corbasson and the Online Distributed ...   \n",
       "6  Produced by Curtis Weyant, Martin Pettit and t...   \n",
       "7  Produced by Michael Roe and the Online Distrib...   \n",
       "\n",
       "                                                Text       Genre  \\\n",
       "0  PREFACE.\\nList of Illustrations.\\nChapter: I.,...     Fiction   \n",
       "1  The Awakeningand Selected Short Stories\\nby Ka...     Fiction   \n",
       "2  NORTH AND SOUTH.\\nâSHE LAY CURLED UPON THE SOF...     Fiction   \n",
       "3  Wuthering Heights\\nby Emily BrontÃ«\\nCHAPTER I\\...     Fiction   \n",
       "4  This etext was produced by\\nAmy E Zelmer  <a.z...  Nonfiction   \n",
       "5  To the reader\\nFootnotes\\n1\\nENFRANCHISEMENT O...  Nonfiction   \n",
       "6  Distributed Proofreading Team at http://www.pg...  Nonfiction   \n",
       "7  Proofreading Team at https://www.pgdp.net (Thi...  Nonfiction   \n",
       "\n",
       "                                        Cleaned_Text  \\\n",
       "0  preface list illustrations chapter ii iii iv v...   \n",
       "1  awakeningand selected short stories kate chopi...   \n",
       "2  north south âshe lay curled upon sofa back dra...   \n",
       "3  wuthering heights emily brontÃ« chapter 1801âi ...   \n",
       "4  etext produced amy e zelmer azelmercqueduau co...   \n",
       "5  reader footnotes 1 enfranchisement women mrs j...   \n",
       "6  distributed proofreading team httpwwwpgdpnet p...   \n",
       "7  proofreading team httpswwwpgdpnet file produce...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [preface, list, illustrations, chapter, ii, ii...  \n",
       "1  [awakeningand, selected, short, stories, kate,...  \n",
       "2  [north, south, âshe, lay, curled, upon, sofa, ...  \n",
       "3  [wuthering, heights, emily, brontÃ«, chapter, 1...  \n",
       "4  [etext, produced, amy, e, zelmer, azelmercqued...  \n",
       "5  [reader, footnotes, 1, enfranchisement, women,...  \n",
       "6  [distributed, proofreading, team, httpwwwpgdpn...  \n",
       "7  [proofreading, team, httpswwwpgdpnet, file, pr...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42334669",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6703c92",
   "metadata": {},
   "source": [
    "##### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf928c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pull descriptive statistics from clean, tokenized text\n",
    "def descriptive_stats(tokens, title, num_tokens=5, verbose=True):\n",
    "    if verbose:\n",
    "        print(f\"Descriptive statistics for '{title}':\")\n",
    "        print(f\"There are {len(tokens)} tokens in the text.\")\n",
    "        print(f\"There are {len(set(tokens))} unique tokens in the text.\")\n",
    "        print(f\"There are {len(''.join(tokens))} characters in the text.\")\n",
    "        print(f\"The lexical diversity is {len(set(tokens))/len(tokens):.3f} in the text.\")\n",
    "\n",
    "        counts = Counter(tokens)\n",
    "\n",
    "        if num_tokens > 0 : \n",
    "            print(counts.most_common(num_tokens))\n",
    "            print('\\n') # add spacing for cleaner output\n",
    "        \n",
    "    return([len(tokens),\n",
    "            len(set(tokens)),\n",
    "            len(\"\".join(tokens)),\n",
    "            len(set(tokens))/len(tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa5b9521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics for 'Pride and Prejudice':\n",
      "There are 59460 tokens in the text.\n",
      "There are 8684 unique tokens in the text.\n",
      "There are 373076 characters in the text.\n",
      "The lexical diversity is 0.146 in the text.\n",
      "[('mr', 780), ('elizabeth', 580), ('could', 527), ('would', 480), ('said', 380), ('darcy', 356), ('mrs', 346), ('much', 327), ('must', 312), ('miss', 301)]\n",
      "\n",
      "\n",
      "Descriptive statistics for 'The Awakening, and Selected Short Stories':\n",
      "There are 32102 tokens in the text.\n",
      "There are 7732 unique tokens in the text.\n",
      "There are 191489 characters in the text.\n",
      "The lexical diversity is 0.241 in the text.\n",
      "[('edna', 281), ('upon', 259), ('one', 253), ('would', 194), ('little', 186), ('pontellier', 171), ('like', 162), ('said', 160), ('mrs', 159), ('robert', 139)]\n",
      "\n",
      "\n",
      "Descriptive statistics for 'North and South':\n",
      "There are 88256 tokens in the text.\n",
      "There are 13345 unique tokens in the text.\n",
      "There are 508748 characters in the text.\n",
      "The lexical diversity is 0.151 in the text.\n",
      "[('margaret', 1186), ('mr', 947), ('said', 907), ('would', 804), ('could', 604), ('one', 602), ('hale', 492), ('âi', 487), ('thornton', 474), ('mrs', 399)]\n",
      "\n",
      "\n",
      "Descriptive statistics for 'Wuthering Heights':\n",
      "There are 58010 tokens in the text.\n",
      "There are 11419 unique tokens in the text.\n",
      "There are 347045 characters in the text.\n",
      "The lexical diversity is 0.197 in the text.\n",
      "[('would', 441), ('heathcliff', 373), ('said', 367), ('linton', 310), ('catherine', 303), ('mr', 284), ('could', 275), ('one', 270), ('âi', 212), ('shall', 187)]\n",
      "\n",
      "\n",
      "Descriptive statistics for 'A Vindication of the Rights of Woman':\n",
      "There are 42152 tokens in the text.\n",
      "There are 7847 unique tokens in the text.\n",
      "There are 277618 characters in the text.\n",
      "The lexical diversity is 0.186 in the text.\n",
      "[('women', 439), ('man', 304), ('men', 299), ('reason', 261), ('would', 233), ('mind', 229), ('may', 226), ('must', 219), ('virtue', 193), ('woman', 184)]\n",
      "\n",
      "\n",
      "Descriptive statistics for 'Enfranchisement of women':\n",
      "There are 4914 tokens in the text.\n",
      "There are 2250 unique tokens in the text.\n",
      "There are 33246 characters in the text.\n",
      "The lexical diversity is 0.458 in the text.\n",
      "[('women', 113), ('men', 76), ('one', 43), ('even', 32), ('life', 28), ('would', 25), ('man', 23), ('present', 21), ('every', 21), ('power', 21)]\n",
      "\n",
      "\n",
      "Descriptive statistics for 'On Liberty':\n",
      "There are 24155 tokens in the text.\n",
      "There are 6120 unique tokens in the text.\n",
      "There are 166365 characters in the text.\n",
      "The lexical diversity is 0.253 in the text.\n",
      "[('one', 237), ('may', 205), ('opinion', 153), ('would', 137), ('others', 115), ('society', 112), ('persons', 107), ('human', 105), ('even', 103), ('opinions', 103)]\n",
      "\n",
      "\n",
      "Descriptive statistics for 'The Subjection of Women':\n",
      "There are 20275 tokens in the text.\n",
      "There are 5142 unique tokens in the text.\n",
      "There are 135351 characters in the text.\n",
      "The lexical diversity is 0.254 in the text.\n",
      "[('women', 318), ('men', 215), ('one', 205), ('pg', 188), ('would', 140), ('power', 113), ('even', 111), ('may', 106), ('human', 104), ('life', 97)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each title and run descriptive statistics\n",
    "for index, row in books.iterrows():\n",
    "    title = row['Title']\n",
    "    tokens = row['Tokens']\n",
    "    \n",
    "    # Call the descriptive_stats function for each book\n",
    "    descriptive_stats(tokens, title, num_tokens=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ef62a2-314d-4453-a180-403d3ca714b8",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88098b36-65f2-4c50-8741-c402b0cc5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text up by paragraphs (\\n)\n",
    "books_expanded = books.assign(Text=books['Text'].str.split('\\n')).explode('Text').reset_index(drop=True)\n",
    "\n",
    "# Drop irrelevant columns\n",
    "books_expanded = books_expanded.drop(columns=['Cleaned_Text', 'Tokens'])\n",
    "\n",
    "# Remove rows where the Text column doesn't have at least 5 words\n",
    "books_filtered = books_expanded[books_expanded['Text'].str.split().str.len() >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c701113-4e2a-4ac3-aeef-e80d6938db3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bj/4_046k_n1259zwtr2hcbxcbw0000gn/T/ipykernel_4835/264113251.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  books_filtered['Cleaned_Text'] = books_filtered['Text'].apply(pipeline)\n",
      "/var/folders/bj/4_046k_n1259zwtr2hcbxcbw0000gn/T/ipykernel_4835/264113251.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  books_filtered['Tokens'] = books_filtered['Cleaned_Text'].apply(tokenize)\n"
     ]
    }
   ],
   "source": [
    "# Cleans Text\n",
    "books_filtered['Cleaned_Text'] = books_filtered['Text'].apply(pipeline)\n",
    "\n",
    "# Tokenizes Text\n",
    "books_filtered['Tokens'] = books_filtered['Cleaned_Text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfb2bf96-e40b-41ae-a6a4-725f1742e9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Release_Date</th>\n",
       "      <th>Updated_Date</th>\n",
       "      <th>Language</th>\n",
       "      <th>Credits</th>\n",
       "      <th>Text</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>June 1, 1998</td>\n",
       "      <td>June 17, 2024</td>\n",
       "      <td>English</td>\n",
       "      <td>Chuck Greif and the Online Distributed Proofre...</td>\n",
       "      <td>CHISWICK PRESS:âCHARLES WHITTINGHAM AND CO.</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>chiswick pressâcharles whittingham co</td>\n",
       "      <td>[chiswick, pressâcharles, whittingham, co]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>June 1, 1998</td>\n",
       "      <td>June 17, 2024</td>\n",
       "      <td>English</td>\n",
       "      <td>Chuck Greif and the Online Distributed Proofre...</td>\n",
       "      <td>TOOKS COURT, CHANCERY LANE, LONDON.</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>tooks court chancery lane london</td>\n",
       "      <td>[tooks, court, chancery, lane, london]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>June 1, 1998</td>\n",
       "      <td>June 17, 2024</td>\n",
       "      <td>English</td>\n",
       "      <td>Chuck Greif and the Online Distributed Proofre...</td>\n",
       "      <td>Walt Whitman has somewhere a fine and just dis...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>walt whitman somewhere fine distinction âloving</td>\n",
       "      <td>[walt, whitman, somewhere, fine, distinction, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>June 1, 1998</td>\n",
       "      <td>June 17, 2024</td>\n",
       "      <td>English</td>\n",
       "      <td>Chuck Greif and the Online Distributed Proofre...</td>\n",
       "      <td>by allowanceâ and âloving with personal love.â...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>allowanceâ âloving personal loveâ distinction ...</td>\n",
       "      <td>[allowanceâ, âloving, personal, loveâ, distinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>June 1, 1998</td>\n",
       "      <td>June 17, 2024</td>\n",
       "      <td>English</td>\n",
       "      <td>Chuck Greif and the Online Distributed Proofre...</td>\n",
       "      <td>to books as well as to men and women; and in t...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>books well men women case</td>\n",
       "      <td>[books, well, men, women, case]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68597</th>\n",
       "      <td>The Subjection of Women</td>\n",
       "      <td>John Stuart Mill</td>\n",
       "      <td>October 28, 2008</td>\n",
       "      <td>January 25, 2021</td>\n",
       "      <td>English</td>\n",
       "      <td>Produced by Michael Roe and the Online Distrib...</td>\n",
       "      <td>any evil actually caused by it), dries up pro ...</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>evil actually caused dries pro tanto</td>\n",
       "      <td>[evil, actually, caused, dries, pro, tanto]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68598</th>\n",
       "      <td>The Subjection of Women</td>\n",
       "      <td>John Stuart Mill</td>\n",
       "      <td>October 28, 2008</td>\n",
       "      <td>January 25, 2021</td>\n",
       "      <td>English</td>\n",
       "      <td>Produced by Michael Roe and the Online Distrib...</td>\n",
       "      <td>the principal fountain of human happiness, and</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>principal fountain human happiness</td>\n",
       "      <td>[principal, fountain, human, happiness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68599</th>\n",
       "      <td>The Subjection of Women</td>\n",
       "      <td>John Stuart Mill</td>\n",
       "      <td>October 28, 2008</td>\n",
       "      <td>January 25, 2021</td>\n",
       "      <td>English</td>\n",
       "      <td>Produced by Michael Roe and the Online Distrib...</td>\n",
       "      <td>leaves the species less rich, to an inappreciable</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>leaves species less rich inappreciable</td>\n",
       "      <td>[leaves, species, less, rich, inappreciable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68600</th>\n",
       "      <td>The Subjection of Women</td>\n",
       "      <td>John Stuart Mill</td>\n",
       "      <td>October 28, 2008</td>\n",
       "      <td>January 25, 2021</td>\n",
       "      <td>English</td>\n",
       "      <td>Produced by Michael Roe and the Online Distrib...</td>\n",
       "      <td>degree, in all that makes life valuable to the</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>degree makes life valuable</td>\n",
       "      <td>[degree, makes, life, valuable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68606</th>\n",
       "      <td>The Subjection of Women</td>\n",
       "      <td>John Stuart Mill</td>\n",
       "      <td>October 28, 2008</td>\n",
       "      <td>January 25, 2021</td>\n",
       "      <td>English</td>\n",
       "      <td>Produced by Michael Roe and the Online Distrib...</td>\n",
       "      <td>THE FULL PROJECT GUTENBERG LICENSE</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>full project gutenberg license</td>\n",
       "      <td>[full, project, gutenberg, license]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57456 rows Ã 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title            Author      Release_Date  \\\n",
       "80         Pride and Prejudice       Jane Austen      June 1, 1998   \n",
       "81         Pride and Prejudice       Jane Austen      June 1, 1998   \n",
       "85         Pride and Prejudice       Jane Austen      June 1, 1998   \n",
       "86         Pride and Prejudice       Jane Austen      June 1, 1998   \n",
       "87         Pride and Prejudice       Jane Austen      June 1, 1998   \n",
       "...                        ...               ...               ...   \n",
       "68597  The Subjection of Women  John Stuart Mill  October 28, 2008   \n",
       "68598  The Subjection of Women  John Stuart Mill  October 28, 2008   \n",
       "68599  The Subjection of Women  John Stuart Mill  October 28, 2008   \n",
       "68600  The Subjection of Women  John Stuart Mill  October 28, 2008   \n",
       "68606  The Subjection of Women  John Stuart Mill  October 28, 2008   \n",
       "\n",
       "           Updated_Date Language  \\\n",
       "80        June 17, 2024  English   \n",
       "81        June 17, 2024  English   \n",
       "85        June 17, 2024  English   \n",
       "86        June 17, 2024  English   \n",
       "87        June 17, 2024  English   \n",
       "...                 ...      ...   \n",
       "68597  January 25, 2021  English   \n",
       "68598  January 25, 2021  English   \n",
       "68599  January 25, 2021  English   \n",
       "68600  January 25, 2021  English   \n",
       "68606  January 25, 2021  English   \n",
       "\n",
       "                                                 Credits  \\\n",
       "80     Chuck Greif and the Online Distributed Proofre...   \n",
       "81     Chuck Greif and the Online Distributed Proofre...   \n",
       "85     Chuck Greif and the Online Distributed Proofre...   \n",
       "86     Chuck Greif and the Online Distributed Proofre...   \n",
       "87     Chuck Greif and the Online Distributed Proofre...   \n",
       "...                                                  ...   \n",
       "68597  Produced by Michael Roe and the Online Distrib...   \n",
       "68598  Produced by Michael Roe and the Online Distrib...   \n",
       "68599  Produced by Michael Roe and the Online Distrib...   \n",
       "68600  Produced by Michael Roe and the Online Distrib...   \n",
       "68606  Produced by Michael Roe and the Online Distrib...   \n",
       "\n",
       "                                                    Text       Genre  \\\n",
       "80           CHISWICK PRESS:âCHARLES WHITTINGHAM AND CO.     Fiction   \n",
       "81                   TOOKS COURT, CHANCERY LANE, LONDON.     Fiction   \n",
       "85     Walt Whitman has somewhere a fine and just dis...     Fiction   \n",
       "86     by allowanceâ and âloving with personal love.â...     Fiction   \n",
       "87     to books as well as to men and women; and in t...     Fiction   \n",
       "...                                                  ...         ...   \n",
       "68597  any evil actually caused by it), dries up pro ...  Nonfiction   \n",
       "68598     the principal fountain of human happiness, and  Nonfiction   \n",
       "68599  leaves the species less rich, to an inappreciable  Nonfiction   \n",
       "68600     degree, in all that makes life valuable to the  Nonfiction   \n",
       "68606                 THE FULL PROJECT GUTENBERG LICENSE  Nonfiction   \n",
       "\n",
       "                                            Cleaned_Text  \\\n",
       "80                 chiswick pressâcharles whittingham co   \n",
       "81                      tooks court chancery lane london   \n",
       "85       walt whitman somewhere fine distinction âloving   \n",
       "86     allowanceâ âloving personal loveâ distinction ...   \n",
       "87                             books well men women case   \n",
       "...                                                  ...   \n",
       "68597               evil actually caused dries pro tanto   \n",
       "68598                 principal fountain human happiness   \n",
       "68599             leaves species less rich inappreciable   \n",
       "68600                         degree makes life valuable   \n",
       "68606                     full project gutenberg license   \n",
       "\n",
       "                                                  Tokens  \n",
       "80            [chiswick, pressâcharles, whittingham, co]  \n",
       "81                [tooks, court, chancery, lane, london]  \n",
       "85     [walt, whitman, somewhere, fine, distinction, ...  \n",
       "86     [allowanceâ, âloving, personal, loveâ, distinc...  \n",
       "87                       [books, well, men, women, case]  \n",
       "...                                                  ...  \n",
       "68597        [evil, actually, caused, dries, pro, tanto]  \n",
       "68598            [principal, fountain, human, happiness]  \n",
       "68599       [leaves, species, less, rich, inappreciable]  \n",
       "68600                    [degree, makes, life, valuable]  \n",
       "68606                [full, project, gutenberg, license]  \n",
       "\n",
       "[57456 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe40087-0e05-462e-b4e7-ca1d168baef1",
   "metadata": {},
   "source": [
    "#### 1. Linear SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "982c1b64-4f85-4339-9987-d1674a4ef6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training Data  45964\n",
      "Size of Test Data  11492\n"
     ]
    }
   ],
   "source": [
    "# 80/20 Split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(books_filtered['Text'],\n",
    "                                                    books_filtered['Genre'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=books_filtered['Genre'])\n",
    "\n",
    "print('Size of Training Data ', X_train.shape[0])\n",
    "print('Size of Test Data ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "536d3af5-d3b0-43c9-9d4e-ee8768f9db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(min_df = 10, ngram_range=(1,2), stop_words=\"english\")\n",
    "X_train_tf = tfidf.fit_transform(X_train)\n",
    "X_test_tf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbc86a20-9856-4471-91e5-6dfc031b25bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(dual=True, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(dual=True, random_state=123)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(dual=True, random_state=123)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit SVM Model\n",
    "model = LinearSVC(random_state=123, dual=True)\n",
    "model.fit(X_train_tf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "449600f7-ca79-4588-9080-f3169775b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score -  0.8753045596936999\n"
     ]
    }
   ],
   "source": [
    "# Classify Test Data\n",
    "Y_pred = model.predict(X_test_tf)\n",
    "print('Accuracy Score - ', accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "211bc6f1-b60b-40b3-b421-12cc374924aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7131,  661],\n",
       "       [ 772, 2928]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cm = confusion_matrix(Y_test, Y_pred)\n",
    "svm_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e792304-0588-4d3d-a410-9e3adc9aed22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fiction       0.90      0.92      0.91      7792\n",
      "  Nonfiction       0.82      0.79      0.80      3700\n",
      "\n",
      "    accuracy                           0.88     11492\n",
      "   macro avg       0.86      0.85      0.86     11492\n",
      "weighted avg       0.87      0.88      0.87     11492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e756e7-6ee3-41d5-9e1c-e6d697575f4e",
   "metadata": {},
   "source": [
    "#### 2. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abd5d905-c15f-4a3c-947d-a2929fce20d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 8739 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "# Only keep words with 5 or more occurrences\n",
    "word_cutoff = 5\n",
    "\n",
    "tokens = [word for text in books_filtered['Text'] for word in text.split()]\n",
    "\n",
    "# Word Distribution\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "# Create feature words set\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6567f23c-a0bc-4b11-8c9d-d11ab4cb367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :  \n",
    "    # Initialize empty dictionary\n",
    "    ret_dict = {}\n",
    "    \n",
    "    # Split text into tokens\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # For each token:\n",
    "    for word in tokens:\n",
    "        # If word is found in fw, then add to dictionary with value True\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "    \n",
    "    # Return dictionary\n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f35cace-f5d4-482d-86c9-edbfb255ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature set\n",
    "featuresets = [(conv_features(text, feature_words), genre) \n",
    "               for text, genre in zip(books_filtered['Cleaned_Text'], books_filtered['Genre'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8ae73ec-12ee-4a41-aae2-1f03786eef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 split\n",
    "train_set, test_set = train_test_split(featuresets, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37e564ac-43a7-4948-ad09-0c5368dca818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Naive Bayes model\n",
    "clf = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f28bf33-e1a8-44a4-a958-df7104fa508b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8739993038635573\n"
     ]
    }
   ],
   "source": [
    "# Classify Test Data\n",
    "print(nltk.classify.accuracy(clf, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90f6b282-c9d8-41e9-b0c4-d413e7c5264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               political = True           Nonfic : Fictio =    107.8 : 1.0\n",
      "                 virtues = True           Nonfic : Fictio =    107.8 : 1.0\n",
      "                    went = True           Fictio : Nonfic =     79.7 : 1.0\n",
      "                  social = True           Nonfic : Fictio =     66.8 : 1.0\n",
      "                majority = True           Nonfic : Fictio =     58.5 : 1.0\n",
      "              government = True           Nonfic : Fictio =     56.5 : 1.0\n",
      "                equality = True           Nonfic : Fictio =     54.3 : 1.0\n",
      "             sensibility = True           Nonfic : Fictio =     52.9 : 1.0\n",
      "                  attain = True           Nonfic : Fictio =     47.2 : 1.0\n",
      "                morality = True           Nonfic : Fictio =     46.9 : 1.0\n",
      "                    room = True           Fictio : Nonfic =     44.4 : 1.0\n",
      "              cultivated = True           Nonfic : Fictio =     43.0 : 1.0\n",
      "              principles = True           Nonfic : Fictio =     42.0 : 1.0\n",
      "                    aunt = True           Fictio : Nonfic =     41.1 : 1.0\n",
      "                  morals = True           Nonfic : Fictio =     40.2 : 1.0\n",
      "                   night = True           Fictio : Nonfic =     38.9 : 1.0\n",
      "                 acquire = True           Nonfic : Fictio =     37.8 : 1.0\n",
      "                    came = True           Fictio : Nonfic =     37.7 : 1.0\n",
      "           individuality = True           Nonfic : Fictio =     37.4 : 1.0\n",
      "                politics = True           Nonfic : Fictio =     37.4 : 1.0\n",
      "                    bell = True           Fictio : Nonfic =     36.7 : 1.0\n",
      "                    glad = True           Fictio : Nonfic =     36.1 : 1.0\n",
      "                 slavery = True           Nonfic : Fictio =     35.9 : 1.0\n",
      "                   moral = True           Nonfic : Fictio =     34.5 : 1.0\n",
      "                    male = True           Nonfic : Fictio =     34.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Most Informative Features\n",
    "clf.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b01616-95f3-4415-b567-d727adb87ff8",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5617abb7-0d58-4375-ba03-25c0ebcc8cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57456, 7316)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', min_df=5, max_df=0.7)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(books_filtered['Cleaned_Text'])\n",
    "tfidf_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9c45e693-9bb1-4624-95a1-0e30fc1dc768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an LSA (TruncatedSVD) model\n",
    "lsa_model = TruncatedSVD(n_components=2, random_state=123)\n",
    "W_lsa_matrix = lsa_model.fit_transform(tfidf_vectors)\n",
    "H_lsa_matrix = lsa_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ad085fe7-982c-4427-8ba1-9bb86e384b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9aab61ff-493a-438b-81cb-16e9133b2cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  said (3.25)\n",
      "  mr (2.97)\n",
      "  margaret (1.64)\n",
      "  thornton (1.08)\n",
      "  hale (1.00)\n",
      "\n",
      "Topic 01\n",
      "  mr (53.50)\n",
      "  thornton (16.50)\n",
      "  darcy (10.96)\n",
      "  hale (9.59)\n",
      "  bell (5.81)\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_model, tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2683e3d2-02eb-4d25-8dbf-9dec4368ee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bj/4_046k_n1259zwtr2hcbxcbw0000gn/T/ipykernel_4835/542718090.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  books_filtered['lsa_topic'] = W_lsa_matrix.argmax(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_topic</th>\n",
       "      <th>Genre</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>37259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>18480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>1697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lsa_topic       Genre  count\n",
       "0          0     Fiction  37259\n",
       "1          0  Nonfiction  18480\n",
       "2          1     Fiction   1697\n",
       "3          1  Nonfiction     20"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get topic from W matrix for each text\n",
    "books_filtered['lsa_topic'] = W_lsa_matrix.argmax(axis=1)\n",
    "\n",
    "# Count categories by each NMF assigned topic\n",
    "lsa_comparison = books_filtered.groupby(['lsa_topic', 'Genre']).size().reset_index(name='count')\n",
    "lsa_comparison_sort = lsa_comparison.sort_values(by=['lsa_topic', 'count'], ascending=[True, False])\n",
    "lsa_comparison_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d1774-5d69-4aec-8e41-ce8de3ecc95f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
